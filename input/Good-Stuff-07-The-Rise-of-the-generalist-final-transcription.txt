 - Yeah, hit record.  Yeah, so the-- - Jolly good.  - Yeah, no, I had a problem with that.  With our recording pipeline, a couple of days ago,  where I realized it was failing  'cause something had corrupted the,  like the whisper model that I was using.  So it was just shit in the bed every time,  but it's now fixed and I've upgraded it.  So I have like a local whisper server  that I can just hit whenever I want, but--  - I was looking at this the other day, actually,  'cause I was thinking about pulling that from GitHub  and just using, is it good?  - I could send you a note script  that I'll just set everything up for you.  - Okay, that sounds good.  - That's the easiest way to do it, I think.  But I was, yeah, no, it's good.  So I guess for anybody that's,  I was gonna say nobody would be interested in this stuff,  but we literally talk about AI and this is using AI  in an automated fashion for something.  So I guess people would be interested.  If you're probably listening to this,  you might be interested in it.  But yeah, so the purpose of the podcast  was to keep it super simple.  And one of the things we realized after the first episode  is like, oh, hang on a minute.  Even if you've got a file with the audio,  then you need to, like our audio was terrible, right?  It was way too quiet, so we wanted to boost the audio,  but that's quick and easy fix, but you've got to do it.  And then we realized that with the particular mics  that we use, you get like a weird effect  where you'll get a lot of left or a lot of right,  depending on who's talking.  So we wanted to stabilize all that,  so there's more production there.  And then you go to upload the file and you go,  ah, crap, I can't publish anything  'cause I don't have any show notes,  so I can even push it without and then come back to it.  So all of a sudden, there's a bunch of tasks  that you need to do.  So for a few weeks now, we've had all of that  just nice and streamlined and ready to go.  So we record the episode, it drops in a folder,  we run a script, and then everything is taken care of,  so it'll go.  It takes the file, it ups the volume,  it produces from the video an MP3 file to go along with it.  It stabilizes the left right channel output  so that everything sounds quite nicely.  Hopefully you'll have noticed that the audio is much better  in the last couple of ones.  But it'll also then take that MP3 pile  and produce a transcript of what we've said.  So we get a transcript with timestamps  and a transcript without timestamps,  and we use those for different purposes later on.  So for the show notes, we take the timestamp transcript  and we produce all the different sections  of the podcast are all done.  We also produce a hit list of like,  okay, these are areas that might make good clips.  We're not really doing too much with that information  at the moment, but we get it out,  it'll then start to write articles for us  that summarize what we talked about,  and we're pretty gonna just expand this  with more things around what would be,  what are all the different subjects that we covered,  and then what are the good hooks that would go along  with those, and then how would we talk about that  on say social media or somewhere else.  So it gives us a good prompt sheet of things  to post about this going forward.  So yeah, like very much looking at just automating  that whole marketing pipeline,  'cause I don't think either of us like doing marketing.  - It's also, as anyone who has created content will know,  this is just really time consuming.  There's a bunch of steps, a bunch of different outputs  that you're trying to generate.  Each one takes a lot of time.  Like if you're trying to go through,  like I mean, I did this manually really early on.  The first couple of episodes, you go through the episode,  you try and extract bits of,  bits that make good clips for YouTube reels  or TikToks and things like that.  And that is just me re-listening to stuff going,  will this work?  Is this worth putting out on the internet in short form?  And there's a bunch of, yeah, manual process  that just gets baked into this,  which is really time consuming.  And so I guess the objective here was,  how much of this stuff could we just bake into a process  that basically gets kicked off when we take  the video audio file that we generate  from the podcast recording and then we run the script  and it basically produces all of these outputs for us.  And I guess the ideal state we'd like to get to here as well  is sometimes we just bollock on on the podcast  and certainly I'm guilty of this,  not explaining something as clearly or as articulately  as I possibly could.  Maybe there's a good example that comes to me later.  You know, often I'm driving home after this and I'm like,  "Oh, that would have been a really good analogy to use then."  And so we might look at something like 11 Labs  and building voice clones where we can then  essentially take that transcript from the episode,  identify what would make really good short form clips,  re-script some of that stuff so it's like essentially  repurposed for a YouTube reel that's 30 seconds  or it's a minute or something like that.  But it's essentially purpose built.  And then that script gets fed into our 11 Labs voice clone  so that we actually don't need to sit  and rerecord a bunch of stuff.  And yeah, I think that just gives us the ability to go  and produce like shitloads of content.  Like I think that's the, you know,  not necessarily it's gonna spam all of it,  but I think it gives us the ability to just produce content  at scale without us necessarily wasting.  - The question is, is it spam if it's on LinkedIn?  Like what's the bit that's not spam?  - All right, it's all spam.  Take it back immediately.  But I think if you think about it,  like there's just a huge amount of leverage here, right?  It's like the ability to go and generate huge amounts  of content from source material  that would otherwise take, I don't know,  hours and hours and hours, a manual process.  - Well, I think there's a turning out  this could be a good Fred, so let's intro.  Welcome to the good stuff.  - We're episode seven.  - Episode seven.  - We're over the hurdle.  - We don't know what we're gonna call this one yet.  So we'll hopefully at some point in this discussion  then the title will naturally emerge.  - Like last week.  - Yeah.  So I think this is more broadly applicable as well, right?  'Cause we looked at this before  for like knowledge capture systems  or how do you, for knowledge management in an organization,  you've got a whole bunch of ideas.  There's a whole bunch of discussions  that are constantly going on.  Like how do you then share those across the organization?  How do people keep up?  If you're not in a meeting,  have you missed what's going on?  Like can we take transcripts of meetings, pull out,  particular like entities and facts and interesting moments  and then turn those into clips or podcasts  or whatever that can be shared.  Like this is all quite doable with this  and interesting ways to improve that communication layer  inside the business, which I think is quite,  I mean particularly then you match it  with your graph databases and whatnot.  - Exactly.  - Like a bit of like solid entity extraction  to figure out what is actually being discussed here  and what's the other relevant information  that we know about this.  - Yeah, I mean, if you think about like  what an organization is, right?  It's essentially just a collection of knowledge that exists.  And one of the challenges that you get inside,  especially larger organizations, mid-sized companies,  is that there's often skill and knowledge  that is wrapped up in key people, right?  And then those key people leave the business  and you somehow have to go and like, you know,  bridge whatever that knowledge gap is  and then maybe you bring someone else in  who's knowledge might be roughly similar,  but maybe there's like, you know,  a few bits around the edge that's missing  from like a lack of experience within the company  and then, you know, things just are done  a little bit differently, but you could capture all of that,  that knowledge, that information,  and then as you say, you store it in this dynamic memory  via a knowledge graph.  And then the organization is just this like  living, breathing, dynamic entity  that is constantly compounding the collective knowledge  of all of the people within it.  - Yeah, and you could give that, you know,  you can almost give that a name and a persona  and like you can talk to it and ask questions  and it can like give you, I don't know,  like company recaps on a weekly basis.  You just get your podcast on the way to work.  I don't, I'm sure we'll build out all this stuff.  - It depends on the form factor that people most want.  I think that's the best thing, right?  Is that not everyone's gonna wanna listen to it.  Some people might want like, you know,  to read just a quick, you know, palm card summary  of what's been happening in the organization.  Others might want, you know, persona-driven podcast  and other people might just wanna like,  just send me a bunch of tweets  from people in the organization.  Like, it just depends on the form factor.  It's like, how do you wanna conceal that?  - I like the idea that like,  if you did have records of all these things  and somebody left the organization,  instead of like, you know, having to give them a ring up  afterwards and take them out for coffee  to figure something out, you say,  "Oh, well, I'll just talk to your like, virtual avatar."  It's like, it's a bit creepy, like, I mean,  that's why you don't give it the same name  and face and stuff, but you know, it's like,  if there's company knowledge there  that you need to discuss with,  you can just discuss with the AI as opposed to that.  I mean, that sounds like a good use case.  - Yeah.  - I'm not gonna rush to build it right now  unless somebody, like, asks us for it.  - Yeah, as in you've got like--  - I can see how you can do that.  - Your own digital twin that lives within.  - Well, it's, I mean,  we had this notion at Stackware, right,  was we discussed it was you'd have different  sort of graphs of knowledge at different levels.  So there's your personal graph, which is just yours,  and should live entirely on infrastructure that you own.  - Yep.  - And that would be all of your personal things  and your core knowledge, right?  But then there's the stuff that you're discussing  amongst a team or a project or something like that,  that's actually shared knowledge across that project.  It's just that for the most part,  we don't write stuff down,  but if you take all of the instant messages  and the emails and the phone calls and whatnot,  you can start to build a graph of what the knowledge base is  inside that team or that project,  and that could persist beyond you.  And then you would have the team level  and then the public level potentially above that,  where the public one is just the accumulated knowledge  we can scrape from the internet about a subject.  And then you can pull that into different agents  and frameworks to ask questions of that.  It's all, I mean, we talked about it as in the Hive process  that I was working on.  One of the concepts was around having like,  the equivalent of Jamie from Joe Rogan,  but he's an architect now.  - Yeah.  - All right, and you could give him a ring and say,  or have him join a call between,  so this would have been say like between myself and Paul,  and we would talk about the architecture  of a new system component,  and he would just listen in on the call  and do live transcriptions and lookups against the graph  to then present us information in the call  that was relevant to what we were discussing.  So you're talking about this part of the system.  Here's the system diagram for this part of the system.  Like you're saying that you wanna make this change.  Here's the flow on impacts of this change.  Like here's a problem that you're gonna have  if you go down this route.  Here's a risk that you're not identifying.  And so, and just have something that you can provide  that's like really rich contextual information,  like live real-time.  I didn't get it working real-time.  I had like a post discussion version  where you could take the call, run the transcript,  do the entity extraction,  and then get back like an analysis of the conversation  that you just had about a feature.  So could write feature briefs.  You could do a risk analysis.  You could do like architecture reviews  on things that you talk about in the call.  But I think it would just get a lot more natural  if you had that running real-time  like with somebody interacting with you in the call.  Like that would be the key angle.  - But the big benefit there is you've got this  like huge reservoir of contextual memory  that is enabling these agents to just continue  to essentially self-improve over time as well.  And keep adding to that contextual memory as well  with every interaction that you have with it  and others within the organization have with it.  That becomes really powerful.  - I don't know if you saw this one.  I shared this on Sphinx,  but it was Pablo writes all the stuff in Nostra fame.  As he's released his 10X agent framework  that he's been working on after sovereign engineering.  I swear I'm going to have to go  to the sovereign engineering next year  if I can get away with it.  It looks so much fun.  - Just walk us through it.  - So what he's done is he's got a set of agents  that will run away and like,  so he will give like an agent a task.  Or he says, this is what I can infer from the friend anyway.  So you give a task and it will then be done  by one or more agents on Nostra.  So the task becomes like an event on Nostra.  And then you get like a thread of replies  where like say, let's say four or five agents  will come along and try and solve that problem.  And then he can choose which one he likes  as the solution to it,  but also give feedback to it and then go down that thread.  And he could potentially do that  with two or more different threads  and then decide like, okay, that one's not working anymore.  This one is working.  And what you've got is this map of like from your problem,  all the different attempts to solve that problem,  the different paths that you've gone down  and all the human replies that he's made  that teaches the thing how to get better.  And I was like, oh shit, that's like,  that is gonna be such an amazing database  to then use to start improving these things going forwards  because you're now baking in the use of the agent  plus the human feedback that's supervising it  to make it better.  And then you use that for like reinforcement learning  or potentially producing like a graph neural net  about like how would we solve these particular problem type?  And everything is available on Nostra,  everything is like linkable and addressable.  Everything, we know exactly like which agent did what,  we know what all the system prompts are  for all the different agents.  And it's like, this is a hell of a data set.  - Yeah, that's really interesting  because I'm not sure if you'd agree with this,  but like often one of the criticisms  that gets thrown around about language models  is that they're potentially not that good  at helping solve novel problems, right?  And I suspect some of that is like a memory problem, right?  This is not enough contextual memory potentially,  but that seems like a really interesting solution to that.  - Yeah, like I think it would say,  I think it's gonna give you much, much better models  very quickly.  I mean, on the solving of problems thing, it doesn't,  this feels to me like one of those same situations  that we come across quite a lot,  where people say, oh, it can't do this.  And like what they've done is just said, do this.  And then because it doesn't instantly spit out  like the exact answer, it's just written off.  And you would go like, but like, if you got,  like let's say you had this particularly like hard bug  that you needed to solve,  or you're re-architecting this system component,  or you needed to do something that was quite unique,  would you get like even the best person in the world,  you come in and go, how do you solve this now?  - Yeah.  - No, no, no paper, nothing, just solve it.  Like, no, no process.  You're just gonna tell me the answer.  And it would just be so unnatural.  Like, why would we expect this to work?  Whereas like what you would do is you would go, huh,  oh, I don't know.  And you would spend like a long time  trying to break down that problem into component parts  and different strategies.  You might have like five or six different like threads  that you would take.  You would start to, you know, like proof of concept out  a few different parts of those threads.  And then you throw that away because it didn't work  or it did work, but it wouldn't work in the context  that you bring it back to.  And then eventually you would come up with something  and it might take you like, I don't know, months  to solve these things.  And that would seem perfectly reasonable for a human,  but the constraint that we would apply to the LLM  before we write it off as being unable to do this is,  can't even do this in 40 seconds.  - Yeah.  - It's like half an hour.  Like we're gonna have three sort of things.  - The process that requires trial and error  and experimentation is inherently part of that process  that you can't skip.  - So we had that conversation with Gav recently, right?  Shout out Gav.  Friend of the pot.  - Friend of the pot.  (laughing)  - If you're listening to this Gav, you know, give us a boost.  Listen on fountain, you can send us sats.  - Oh, there you go.  - Oh yeah, I set that up the other day.  Like nobody's sent us sats yet.  (laughing)  - There's still time.  - One day, if you're listening and you haven't sent us sats  on fountain, like, you know, there's your, there's your.  - Call to action, right?  - Call to action, yeah.  (laughing)  What was I about to say?  Yeah, so, yeah, he talked about it in terms of creativity,  right, so the guy, he's a very creative guy.  I love his like stuff that he posts on LinkedIn.  He's like one of the few people that's kind of unique  in that, in that space.  - He's right, like he said, like, you know,  creativity can be taught.  - Yeah.  - It's a skill that you can, you can learn  and it's really comes down to a process that you go through.  And if you push yourself through that process,  then you'll end up being more creative and.  - Yeah.  - Like any like author that I've listened to about,  you know, writing and the processes,  it always seems to come down to, you know,  you just got to turn up and sit in front of a page  and then sit there until there's like a thousand words  on the page.  And if you get really carried away, keep going.  But, but as a minimum, you just need to set up every day  and put pen to paper and it turns out you'll get way better  at writing if you just keep doing that.  - Yeah.  - You're like, yeah, like there's, I think there's a,  similarly there is a process to solving problems.  It's very abstract and we just give a lot of freedom  and space to people that do it.  And it's not clear how we would codify that  into AI systems yet, but there's nothing unique  that would stop us coding that into AI systems.  And then the difference is that where we might need to give,  you know, free months and, you know, a hundred grand  to somebody to solve this problem previously,  now it becomes a, all right, it's a week's worth of computes  that costs two grand.  And to run, like, you know, if you were going to run  a two grand compute job, you'd be like,  God, this doesn't, this feels like a lot.  'Cause it's just such a different like level of spend  than you're used to for just running.  You know, I've got a $20 subscription.  Like, why do I need to pay more than that?  But then I don't know, I had a similar--  - The equivalent is how many people do you have sat  in the office that are thinking about this problem  and how long do they spend thinking about it?  - Well, and we're quite forgiving  to the human component of this, right?  Whereas we would spend like a hundred grand on that  and then go, I didn't work.  Oh, well, you know, we got the best guys in  and they could do it.  Like, so at a minimum, you should, you know,  if you're going to do the hundred grand one,  also do the two grand version  and just leave a machine thinking for timing.  - Yeah, it's the classic me and why not both?  - Yeah, so I mean, that's one component of it.  I know I had a similar, I was reluctant to go buy  like the OpenAI Pro model.  And I did it in the end,  'cause I wanted to generate some videos for my daughter.  And I barely used it for that,  'cause it's actually a bit crap.  It turns out.  - Yeah.  - But it really is a good researcher.  Like if I've got like just something that I want to know  or I'm designing a new feature or something  where it's not clear to me exactly what the answer is,  I know that all the information is out there on the internet.  And I know that if I spent like a week dealing with this,  like I could probably come up with a good view of it.  Or before I drive somewhere,  I can just give the instructions to O for a deep research.  It asks me back five questions to clarify.  I say, here's all the answers to that.  And then I just let it go.  And it can come up with novel strategies  for how to solve stuff that I need.  And then I take that and then I use that  as a plan to move forward.  - Yeah, I think the framing and the context  is really important there though.  There's maybe a meta level skill for the human here  is how to think.  And I think actually what you've described,  you've just made a case for why I think  generalists will win.  And there's maybe some framing here.  - I feel like I'm a generalist, so this is good news.  - Yeah, me too.  And so maybe I'm speaking my own book here a little bit,  but I think that's what I'm hearing  in what you're describing there, right?  It's, but what I will say is like you mentioned,  you mentioned earlier this framing of,  oh, chat GPT doesn't do my job, therefore,  this isn't gonna be the right tool for what we need.  And it's funny, I was thinking about this recently  and I was having this conversation  with a friend of mine last weekend.  There's almost this like, I'd say near unanimity  in the types of responses people will give  to this question of will AI take your job?  Like when you ask someone point blank,  will it take your job?  What you think your job is?  Will it take it?  Like I would say almost always,  especially outside of a tech circle,  people will say no and they're definitive about it.  I'm yet to really have a conversation  with someone outside of tech that has gone,  do you know what?  Yeah, I believe AI will definitely take my job.  And I think what's interesting is they will often justify it  by citing some like unique kernel of knowledge  that they've built up through compound effort over time.  Or there's some like unique aspect to their job  or that they've just tried chat GPT  and they said do my job and it didn't do it.  And I think what's really interesting there is  they've honed in on like a unique subcomponent of their job  to justify why the totality of the job  won't be taken by AI without realizing  that actually what you need to do is decompose that job  into its subatomic form.  And then that highlights a bunch of individualized  like, you know, individual tasks that then an agent  can do in perpetuity.  And I think that the, again, this is where I think  the framing really matters is like once you decompose  those tasks into its subatomic form,  you can then assess to what degree like an agent  or I just say AI can actually perform  that one subatomic task.  Then you can assess what is the like error rate  of that agent or that AI versus what like  the relative human error rate is, right?  'Cause there's always like a human error rate.  We just kind of--  - Yeah, we just brush it off.  - Brush it off, right?  And then I think the assessment of those two rates of error  gives you like an acceptable rate of error, right?  It's like what's the AI rate of error relative  to the human rate of error and let's try  and like find an acceptable point in the middle.  - One of the things that we do for human error  is we would introduce a manager and say check the work.  - We can introduce AI managers as well,  like there's ways to check stuff.  - And then it's like the question is like,  okay, what's the upside then of now being able  to do this subatomic task repeatedly,  you know, in perpetuity at the kind of speed  and velocity that can't be matched by human  because now we've just taken a part of your job  and we just put it on autopilot and it's being done  even when you're not in the office,  even when you're not at work.  - So I think this is where the intelligent assembly line  is the goal, right?  Because if you think about it from like a bionic human  point of view, it's not that useful.  I mean, it is useful if there's a particular point  of my job, like in my eight hour day,  there was a point that used to take an hour  and now it takes five minutes.  - Yep.  - That's great, but it's not an absolute game changer  because nothing else has really changed  'cause the whole job was built around that container  of a person that you require to get the stuff done.  So I think when you start to speed up all those  individual components, what you start to realize is,  oh, I can like massively accelerate all these things,  but I get no benefit from this  because I still have to just put them all into a human.  So basically what you've done is turned like  somebody that used to do intelligent work for you  into a machine that drinks coffee  and watches work get done.  And if you're at that point, you'd have to say like,  okay, well, I need to re-architect this a little bit  'cause there's no point in like the person just waiting  around or the machine waiting around  for the person to be there through the work.  We need to rethink the process from a machine-first  point of view and then what are the edge cases  that we burst out to humans where we need them  and how do we deal with that?  - But I think there's an assumption here  that's wrapped into this, right?  It's like, if AI, this question of like,  will AI take my job is just essentially a binary, right?  It's either like 100% at will or it can't.  And I just think that is like too simplistic a framing here,  but that's how we all think about it.  And so there's almost this, like we've talked about  the kind of language label load heuristics  for the organization, at a kind of meta level.  That assesses the degree of applicability for AI  within the processes in that business.  But I think you can apply a similar set of heuristics  to a job function.  And then that gives you this question of like,  okay, at what percent of the tasks that Joe does  in his job function, does it equate to that job  being done in its totality by AI?  And by that I just mean like, okay,  maybe the answer isn't 100% of your job  means you lose your job to AI.  Maybe it's just 20 to 30% of the tasks you used to do  are now automated away.  And so this has a bunch of like second order effects  inside the organization because now all of a sudden you go,  well, hang on, like we've got a bunch of people  who do the same job.  Maybe some of these roles can now be like combined  or consolidated.  So that means just fewer people within that company  are required because one person can do  what three people were doing previously.  And then of course you get the second,  the third order effects are kind of a more macro level  is like, what happens if now you've got a bunch of  excess supply for a job function in a market?  Well, that over time should probably drive down  the value of that work,  the price that a company is prepared to pay for it  because there's an abundance of people who can do the work.  And so even if you just essentially give people tools,  you still end up with this value trap effect  in the long term because you're gonna drive down  the price that companies are prepared to pay for that labor  because there's just an abundance of it.  So then I guess to wrap this,  the question is like if 30% of your tasks  within your job function are taken by AI,  does it mean that AI has taken your job?  - I mean, it's certainly taken 30% of it, right?  - Yeah, the question is like when you factor all the second  and third order effects of losing 30% of that job function,  like what happens?  How does that, like it's the game theory  of how that plays out, I think.  - I mean, if we just take the magic words AI or letters,  AI after this, and we just sort of said like,  all right, well, is there any other historical context  that we could look at around just technology?  And like this has been the relentless,  you know, pursuit of technology for the whole time,  like just this constant taking of work away from people.  You're saying like, we've always used software  and hardware and other technology really  just to speed up the amount of work that we had.  So let's say in the production of a car,  at some point you would have said like,  all right, well, the car can only put the body panels on,  like this robot can only do the body panels,  and this robot can only tie in screws,  and this robot can only do this.  And then what you saw is that, like, yeah,  one of those robots couldn't take you a job.  It turns out a few hundred of them in a line  can take you a job,  'cause we can then mechanize the assembly line.  Like, so again, I think the intelligent assembly line  comes out there and like, that's how it starts to,  that's how you end up pushing into that space  where it does take jobs.  But even when you first have that, like, you know,  you would have had like a bunch of robots  that just did parts of the work and then it went to humans,  and what it meant was just the whole system  required less input.  And it's not that, like, people just hang around  and don't do anything, like, the person just moves on  to the next most valuable task that you can do,  which is great, that's what you want people to do.  I mean, the bit that will be interesting is like,  all right, I wonder, as we start automating out  a lot of these intellectual tasks,  assuming this works, I think we still end up with like,  like, there's a set of tasks that are just so unique  that humans just happen to be the best for a while.  Like, I still, I don't see why it's protected long-term,  like, it's hard to me to think that like,  you can't replicate the process for problem solving,  creativity, uniqueness, just by massive amounts  of brute force and randomness.  Like, you know, evolution's done a pretty fucking good job  of giving us exactly all the right natural things  that we need to exist in this environment.  And like, we seem to get a bunch of problems coming up  when we don't respect, like, a lot of those things  that evolution gave us.  So I think you could just run that on compute, you know,  just on a computer time scale and move way more quickly  through that process for any sort of problem solving  and finding a fit.  - I think in the same way, though,  like, if you look at like, email coming along,  it didn't necessarily kill off the secretary,  but it did essentially remove the need  for the typing pools and mail distribution centers.  And like, so if you're working in those kinds of roles,  it's more like administrative typing.  - I never got my pneumatic tube.  - There you go.  You know?  And I think this is like an interesting point about this.  It's because like this shift that is occurring,  because it occurs at a subatomic level,  it is easier to miss because there's like more  of a kind of gradual displacement that's occurring.  And so today it's two of my tasks  that get like essentially automated away.  And then next month, maybe it's another one or two.  Next year, maybe it's all of a sudden  it's like 50% of my tasks.  And I think that's, it's like slowly all, you know,  slowly until it's not.  And then it's like all at once.  And maybe that's part of the challenge  for a lot of people not seeing the kind of displacement.  - I think that's why there's a blind spot for this  is that like you view your job as a whole,  your job isn't a whole, it's 200 different jobs.  And any one of them is automatable.  It's, if it just, there's a question around  whether it's worthwhile to go through that.  So some jobs are gonna get done quicker than others.  Like, you know, the amount of money that gets paid  to software engineers globally is huge.  Plus software engineers are really into software.  And they're quite happy to automate away their jobs.  They've been doing it for years.  It's kind of the way they operate.  So it's not really a surprise that there's so much effort  going into automating coding right now.  - Yeah, completely.  - It aligns quite nicely.  But it's, I almost think if you can solve that problem,  everything else is probably gonna seem a little bit simple.  And then it's just a case of writing all the tooling  to get it done.  But again, it makes you wonder like what remains  at the end of this, right?  - Well, this is the link to generalism,  I think to some degree, right?  I think the skills required shift.  So we mentioned like there's this meta skill  around how to think.  You know, I think there's like maybe this like differential  between like fixed mindset and growth mindset  becomes like economically determinative.  And I guess like what I mean there is you hit  an inflection point where like those skills matter more.  You know, it's like how adaptable are you?  How open-minded are you?  How open to learning?  But I can make a really adaptable open-minded AI agent.  Like I wonder like why would that be?  - But it's about what problems you wanna go and solve, right?  So it's like, okay, so I think like generalists  I think work really well when you're like operate  in these like kind of environments that have,  you know, essentially few or no rules, right?  They're pretty fluxy.  I think--  - Maybe like here's another one, right?  So for entrepreneurs, risk tolerance is a huge thing.  Like does an AI have risk tolerance or not?  And how does it judge that?  Or like, I mean, people talk about taste.  I feel like taste I could probably brute force  by A/B testing a whole bunch of stuff.  So I'm not, I don't know if that's that defensible.  Like I think what to build  and just having some sort of intent in the world  is like intent and risk tolerance and like owning  of capital, like they feel like they're gonna be harder  to dislodge just because humans have got all the money  right now.  So at some point, even if AIs have money to spend on stuff,  my assumption here is that it will be the humans have money  and they give them to the AIs to accomplish jobs  because the AI has no desire or intent of its own.  It needs to get it from somewhere.  Now, does that go out the window?  If somebody just says like, all right, go and build me  do you take over the world and turn everyone into paperclips?  I don't know.  I don't know if that's useful for the exercise.  - I think that's like the right framing.  I guess the point I was trying to make about generalism  is that like we're in this environment now  where it becomes less about like knowing the exact answer  to a particular, any particular question.  And instead it's more about knowing  like which questions to ask.  And so that's where I think, you know, the adaptability  and the open-mindedness, the willingness to learn  like how perceptive are you  to all of these changes that are occurring around you.  These are the things that like enable agency.  And then you can use the technology that's around you  in meaningful ways.  I think this is why we've talked about, you know,  I mean, I'm framing this as like, you know,  generalism more broadly, but I think this is also,  this also underpins why we think this is like a golden age  for entrepreneurs as well to some degree.  - I do wonder if we're maybe also thinking  on different timescales.  Like, it's not obvious to me that there's any,  any of that is still exists in 20 to 50 years, for instance.  But if you said like, what are the skills you really want  in the next five, I would say absolutely,  like you want to be very general, very adaptable,  like because the things that this can do will keep changing.  And then you will need to keep moving  to the things that it is not doing.  And it's not to say that it won't get to those things,  but there's definitely going to be like a diffusion  of tool build out here, where we'll start in one space  and then we'll move to the others.  So I think long-term, like a lot of the sort of work is done,  like of any intelligent work is done by these machines  in some way or another.  And then, you know, at some point I guess we'll fall back  to being the manual work, but even that,  like we already know that we can outsource a lot of that.  That's what car manufacturing plants  and various things are told us, like, you know,  do we even need like a general humanoid robot  or could you just have like a floating spanner  that does all the floating spanner tasks,  a floating screwdriver that just flies around  and screws in screws?  Like, it doesn't need to be so general purpose  that it can be put everywhere.  But yeah, I think really the focus,  like if you were planning for this would be on,  I need to be adaptable.  I need to understand the constraints  of what this thing can do and can't do  and then I need to fill in the gaps.  - Yeah, they're transition period skills, right?  - I think so.  - 'Cause I think the caveat here that I would certainly apply  is like, it's probably not even worth trying  to think beyond five years.  'Cause we just can't-  - It's basically in the world of magic at this point, right?  It's like, well, how good do these things go?  Like, there's not an obvious stopper for me on this.  I don't think like the things that get thrown up around,  like, oh, it can't be creative.  It's like, I think that's nonsense.  I think that really comes down to observing  what's going on in reality, derivative works, randomness,  and then trying shit and seeing what works.  - Yeah, I think-  - Like there's a process around it.  - Some of that also comes out of people's experience  using a language model like TragicVt.  It's like a very broad-based,  general probabilistic tool, you know?  So it's probably not the thing that's gonna give you-  - And the bias to like, now.  It's like, do it now, as opposed to like,  'cause I think if you sit with chat GPT  and you spend days, like, prompting it,  listening to what it says, starting a new chat,  re-prompting it, going down a different alley,  pulling up on that one, starting again,  doing a new chat, running a deep research,  coming back again.  Like, you can do all these things.  Like, it can be creative if you push it through the process.  I mean, once you recognize that you can push it  through the process manually,  well, there's no reason why you couldn't push it  through the process automatically, much quicker,  at which point.  - How do you think about-  - Maybe we should build a problem-solving workflow  that just costs like, I don't know,  a thousand dollars a pop.  People can just run it and see what they get.  - It'd be interesting, wouldn't it?  I mean, it depends on like the,  I think, again, the type of questions that you're asking.  That's like a high value skill to just have,  knowing what to ask in a really uncertain environment.  And, you know, again, that's contextual, right?  Because generalists have like,  they have a little bit of knowledge  from a bunch of different disciplines.  And so that gives you this kind of varied  contextual understanding of how things are done  in different ways in different places.  And you can apply that to a particular problem  that's staring you in the face right now.  Whereas, yeah, I think that's one of the challenges  with specialists.  It's very domain heavy.  It's compounded knowledge over a long period of time.  And so you know exactly how to solve a particular problem  as it's presented to you.  And maybe that's the distinction.  It's like, as you drive down the price of intelligence,  then, you know, that intelligent form now  knows the answer to that question as well.  But it's vastly cheaper to access.  - Well, there's another like massive benefit here  to taking that domain of expertise and knowledge  and moving it from a human's head into a computer,  which is that computers are very good at networking  in a way that we're not.  You know, like once you've established this  in one place somewhere,  it's only down to the intent of the person controlling  that computer program, whether everybody else in the world  has access to that information or not.  So you could solve a problem once somewhere in the world.  I would say that I'm sure if we were able to like somehow,  you know, we were the plasters demon or whatever,  and we're able to like just look at the world  and just understand in the moment,  like how many people in the world right now  are attempting to solve problems  that have already been solved  because they're just unknown to them.  - Yes.  - And I would be surprised if it's not somewhere  in the high 90s, like all the time.  - That's right.  - Just imagine if you could just solve the problem once,  it becomes somehow addressable and discoverable  on the internet.  And then now anybody else that wants to do the problem,  they already have the solution to that problem.  It's already been codified and put in.  They know they can run it again and get the same answer.  Fuck, that's like, you just,  that doesn't exist in nature with us, right?  Like we, the best we've got is that you solve it  and then you'd have to spend all your time talking about it  to then have a discovery problem  of how does the person even discover you to listen to you  in the moment, like it's so inefficient,  the way that in that problem solving like capacity  just spreads, that's gonna be fucking.  - Yeah, it's like, how do you build the pyramids  in different parts of the world at roughly the same time?  It's because that intelligence is network somehow, right?  - Is this you wanting to get back to--  - Conspiracy corner.  - Conspiracy corner.  - Always.  - I mean, mushrooms.  - We should have like a separate part of the conspiracy.  - No, but that's, I'm being a little bit facetious,  but it's like, yeah, that's essentially it, right?  It's how do we basically tap into combined human knowledge  or collective intelligence that's contextualized  from someone trying to solve a problem anywhere in the world  because presumably someone somewhere else  is gonna have the same problem  or some sort of similar problem.  And you're right, a lot of business is just building  the nth version of stuff that already exists  because there's a large enough market  to go and like potentially compete away  some return that exists in that market.  - So is there like a skill here to just like crows  in Australia are so Australian,  like they're just the way they, the way they talk,  like crows in the UK never made this noise.  - Yeah.  - It's like, eh, eh, yeah, nah, mate, nah.  (laughing)  That's so Australian, that's so Aussie.  - Very good impression.  - Nah, nah, just down the beach, mate, nah.  I'm gonna get on that podcast.  I'm just gonna shout next to that van.  Eh.  (laughing)  - Oh, really?  - Oh, God.  - That's an amazing impression.  - I have no idea what I was saying.  - That is incredible, I love it.  - Yeah, okay, so maybe there's a skill there around,  that was it, uniqueness.  - Mm, yeah.  - There's, again, I don't know if this is like  defensible, like super long term,  but just this figuring out like what's,  all right, well, assuming we can like solve a problem once  and it's available for everybody,  that's just gonna become an addressability  and discoverability problem,  which computers are better at that, frankly.  Like, how do you figure out like  what the next best thing to do is?  - Well, that's it, that's the matter.  It's like, what is the problem worth solving here?  You know, it's like we, if I just--  - Maybe it's like our thing will be to be in pain,  so that we can go, could you resolve this pain for me?  - Yeah. - It'll go, yeah, cool, done.  Right, and you go, ah, cool, that's good.  Now I have this problem.  - Yeah, what's next? - It's a weird,  like, epicurean thing of just experiencing  really nice things and then going, it's not perfect.  - So this is, to some degree, how we approach  product as well, for other stuff.  It's like, what, we're just scratching our own inches  most of the time, it's like, what is this problem  that I have that I wanna solve?  It's like, we're not trying to go and figure out,  like, build a focus group around, like,  which market should we build this product for?  Like, what's the, you know, minimum viable version of this?  Like, we're just building it to a point  where it solves the problem that we have.  And whether or not that market exists  is purely dependent on how many other people  have the same pain point as us,  who would like that pain point resolved?  Like, that's really as simple as it need be.  - Yeah, well, and then it's worthwhile,  'cause you've resolved your own--  - Exactly. - Right, like, it's just--  - But that's also part of technology-enabling progress,  because in the past, to solve that problem  might have taken, like, a team of people,  million dollars a capital and, like, a year's worth of time  to go and, like, code up, you know, that product.  But now, we've just got this ability to go  and spin this stuff up really quickly.  - We just do it on the side. - Yeah.  - Like, whilst doing other stuff.  - While doing the other stuff.  - It's like, well, this agent's running  to build that program, so I might as well  flip into the other one and start designing my game rules.  - Yeah, precisely.  - Yeah.  - But I do, like, I mean, I must admit,  I kind of don't necessarily enjoy, like,  pontificating on, like, the kind of more doomeress stuff.  But, like, you hear this counterpoint that's made a lot,  that every new technological era, like, kills jobs,  but it creates a whole raft of new ones  that we haven't foreseen yet.  And I guess, like, my question here is,  is, like, is this time different?  - Well, it's, yeah, I've had that.  Actually, I remember a couple of years ago,  like, at Bush Bash having this discussion with Bill.  And I was, I was like, I'm very much in, like,  the pro-technology, pro, like,  people will just find something else to do, generally.  But it does feel like we're taking, like,  like, whole sections of jobs.  Like, we did this with, like, we took a blue collar job.  We took a lot of manual labor jobs,  and they don't exist anymore.  And we say, oh, yeah, but people found other stuff to do,  and they did, you know, they did intellectual jobs.  And you go, yeah, okay.  But now we're taking, like, we're now attacking  the whole category of intellectual jobs.  So where do they, like, where's the obvious bit  that they go to?  And it's really, it's really hard to think through,  like, what's the end game up there?  - I think that's, that's the important distinction here,  is that, like, in the past,  if you look at these, like, technological shifts,  like we talked about in a couple of previous episodes,  you know, the, the agricultural revolution as well,  the mechanization of farming led to more industrialization.  So people were able to gravitate toward the cities,  pick up those jobs as, like, a new technology was emerging  that kind of killed off, you know,  the last major bit of technology  that they benefited from.  This time it's, you know, it's not one industry,  it's not one sector in a broader economy.  It's like pretty much every white-collar industry  that exists, but also it's happening simultaneously  and on a global scale.  - Yeah.  - And I think that's the bit where I'm like, ah, okay.  - So an example I think is interesting,  is people always bring up something like an influencer.  They're saying like, oh, you know,  this is like content creator influencer,  these were jobs that didn't exist, you know,  like 10 years ago.  And you're like, yeah, but even like,  something like an influencer is like, all right,  well, I'm gonna like influence people on what to buy.  It assumes a certain amount of consumerism,  a certain amount of like difficulty and scarcity  in the goods.  And you kind of think like, well, if you had just super,  you know, again, like super,  a lot of intelligence everywhere that's basically free,  a lot of robotics everywhere that becomes basically free  because we'd spend, you know, maybe we spend 10 years  just making the robotics free  because we don't have anything else to do.  But then at that point, you're like, all right,  well, now everything's basically free  and you can have whatever you want.  And the way you would get whatever you want  isn't by somebody influencing you necessarily,  it would just be that you go, oh, I need to, I need this.  I was like, maybe like the last job is experiencer.  And it's like, I'm just gonna experience stuff  and then voice my concerns about what isn't perfect.  Like that's like weirdly dystopian.  - Yeah.  - But it's, yeah, like I think it probably gets  to this point where it's just like, you know,  the stoic in me would say like, just don't like,  there's no, you can't control any of this stuff  in the future.  Like the stuff that is on this like,  I don't know, two to five year time horizon  is influencable and knowable to a certain extent.  You can see what's gonna get replaced first.  You could see how it's gonna get replaced.  So don't do those jobs and then start the businesses  that work in that manner from day one.  - Yeah, but this comes back,  this is like full circle to some degree  'cause the challenge is now  that most people have this like reinforced bias  to believe that the job that they have is somehow special  and that the skill that they have is somehow unique.  - That's just my skills, though, not other people's skills.  (laughing)  I'm always trying to get myself out of a job,  so yeah, well.  - That's it, right?  It's like, what's the most efficient way to do this?  - Maybe the last job is the person  trying to avoid the work.  (laughing)  It's just like you can't let it just be  all the people that never wanted to work  will be the last people working  'cause they put them in jobs  and then they get themselves out of the work.  - Yeah.  I mean, I wonder what,  you know, you expect like a government response  to this as well and there's so many theories  that float around, you know.  Mostly all roads lead to UBI,  but I feel like there's a bunch of different things  that don't-- - I think the great way  to think about that is all roads  lead to massive amounts of inflation.  - Yeah, exactly, I was just gonna say.  - Destroy all sorts of stuff that you need to.  - Yeah.  - If you're gonna worry about it, worry about that.  Like, I've never met a government  that didn't increase the money supply.  - Exactly.  Well, I mean, the first like cab off the rank will be,  let's try and regulate the hell out of this stuff  and try and preserve,  you know, the kind of the status quo as best they can.  I think that leads to a bunch of like, you know,  job keeper type programs that we've seen in the past,  you know, and that's obviously where the money printing  kicks in. - Well, it will be--  - That's even pre-UBI, that's--  - Centralization into government jobs as well.  - Yeah. - Because again,  if you're in government or one of the two parties  that are allowed to govern and you buy into the notion  that like, okay, well, we pay the bills of everybody  and the only jobs that remain are the ones that we pay.  - Well, you have like a very loyal workforce  at this point in time, you know,  who's gonna vote against destroying their own job.  That's just not how it works. - Well, exactly, yeah.  Well, I mean, I think there's almost maybe like  a bigger mathematical problem for governments here as well.  It's like, if all of a sudden you automate like, you know,  huge chunks of knowledge work,  well, you've just like had this massive erosion  of a tax base as well.  I know in Australia, a couple of years ago,  I think like the percentage of federal tax receipts  from individual tax, individual income tax  was like nearly 50% thereabouts.  I mean, that's significant.  So what do you do in that circumstance?  You're gonna print more money, i.e.,  'cause you're not gonna cut spending.  So this is the thing 'cause austerity is just so unpopular.  No one ever votes for austerity.  So they're just gonna have to like vastly increase  the amount of money printing that exists  in order to keep paying for these programs that exist,  probably expand these programs  'cause now more people are out of work  and this is just like a massive spiral.  - I think so.  Government's gonna government.  - Yeah, and probably not what I thought we'd cover,  but I mean, so I think like one of the things  that we've talked about in the past  that kinds of ties into all this  is this notion of the bionic human.  And I think this is like the kind of the bionic human  versus the human at the edge,  which is kind of our framework for assessing whether or not  you just give people a bunch of tools inside of the business.  And then that provides some productivity improvement  versus essentially going back to first principles  and rebuilding process on a kind of AI standard.  I kind of feel like that's where the market's at  at the moment.  They're probably more in the bionic human space  at the moment where they're like,  we'll just give people all of the tools  and we'll get the upside to this.  I think, you know, when I think about this  through the lens of the value trap,  which we did a whole episode on as well.  We can go back and listen to that.  But when I think about this  through the lens of the value trap,  I actually think the bionic human plays out  exactly the same way, but it's worse for the business  because they never actually dropped their cost base  in any meaningful way.  - Yeah.  - And so like, you know, when we talk about  the mean reversion phase in the value trap,  which is basically you've gone  and you've created all of this, you know,  these excess returns and you've simultaneously collapsed  your OPEX in the business.  So you've had this big margin,  but all of the competition emerges to compete that way.  You get this mean reversion later in the cycle.  I think the issue with a bionic human approach  is you essentially just have like a way higher cost line,  which doesn't fall, but the revenue falls way lower.  And so now your business is just losing  shit tons of money and goes under.  - Yeah, like it's, it only works if nobody else  figures out the human at the edge model.  Like I think they're somewhat sequential,  like they don't have to be sequential.  I think the way most people would do it  in an existing business is sequential that you would say,  I don't have time to redesign  all of my processes from scratch.  The first thing I'm gonna do is use these tools  to give myself some head space.  And I actually think that's quite reasonable.  I used to be a bit like, no, no, no, just do this.  Just do the right thing.  And you're like, you know what?  It's not really where the world is at the moment.  And people do just need tools to get their head,  like get some space.  Like you need head space to do these things,  even just to consider it and get comfortable  with the risk of like, shit, I need to redesign everything.  I've been running this thing for 10 years.  You don't just do it over drinks in the evening.  You've got to spend some time on it.  So you've got to find a way to get that space  and you're not gonna have it in most,  even in like larger businesses.  It's rare that you're the person  that gets to spend all the time doing it.  And if you are the person that gets to have all of that time  to think about stuff,  you're probably not the person that's on the tools enough  to understand what's going on.  So it is difficult.  You kind of need to free up a bit of everybody's time  to go through this process and then engage in it.  So I think you'll always see the bionic human first.  I think if you're creating a new organization,  I just wouldn't bother.  I'd skip it and just go straight to the end game.  Like every time you're looking to do something,  you think about, all right,  well, what's the process to produce the thing  that I'm producing and how can I just take people  out of the loop?  - Yeah, I think that's the big risk to the incumbents  is like while they're all trying to figure this stuff out,  you've got a new breed of business that's being spun up  in their industry that's just gonna come and eat that one.  - But then they have the opposing problem  that they just have no market share  and they have no distribution.  So it'll be a race in a way.  Like I think the thing that you'd want to be aware of  is like, all right, well, there is a race.  So I am gonna have to race  and I am gonna have to race against people  that started with no people involved  and built the thing from scratch and then grew.  And there's a question of like, well, what's easier?  Growing or eliminating your own cost base?  - Yeah.  - And that will likely be different in different industries  and different areas as well.  Like some people aren't loyal.  Like if you're buying a service like once a year  or once every couple of years when something goes wrong,  like, I don't know, my air conditioning breaks,  who do I call?  I might call the same person I did before,  but it's pretty much like a new thing every time it happens.  - Yeah.  I mean, I also think there's like a unevenness  that exists in the Bionic human,  the way that plays out as well  because people use tools in different ways.  You know, there's that classic meme where it's like,  you know, you've got the guy sending, you know, the email.  It's like, you know, turn these four bullet points  into like 12 page report.  And then the person on the other end of it is like,  oh God, I don't have time to read this.  Turn this 12 page report into like four bullet points.  You know, and it's like this circularity that exists there,  which is just everyone wasting everyone's time.  - Yup.  - I think that plays out to some degree  with the tools as well.  So it's like the beneficiaries of the tools  are not necessarily all going to be the same.  - Yup.  - But I think it's still like an essential part  of the learning journey for pretty much everybody, right?  So you just see what's possible.  And then that opens your mind.  - Yeah, that's the other aspect  that you just can't say enough almost, right?  It's like you need to, it's hard to go from like zero  to understanding like where all the impacts are.  You know, obviously, you know,  get us into a workshop and we'll tell you about it.  But telling is one thing and showing is a better thing.  So you're better off like try and understand it,  then get on the tools and start doing it  and then start applying it to the problems that you have.  - Yeah.  - Or like what's something that's a bit annoying  that I'd love to solve,  but I've never had the capability, capacity,  intent to solve before, do that.  - Yeah, exactly.  - Just get rid of it.  Remove it from your life completely.  Like with software and automation,  like that's a cool thing.  - Yeah, and there's also like tool choice as well.  You know, there's a commitment that needs to be made around  like do I choose cursor or windsurf?  Are they practically the same?  How do I know if they're the same?  You know, which do I just prefer subjectively?  There's like a whole bunch of learning that,  yeah, or you know, there's a bunch, right.  And that's like, there is a kind of subjective learning  process that you just need to go through.  - Like I'm doing it at the moment  with a lot of the coding work I'm doing is like, again,  it's almost like going back to the work I did with Stackwork  to say like the process is correct.  Like the painful thing about the work with Stackwork  was when you run in this sort of hive model  and you've got so many tasks  with so many different developers  like in your head at any one time.  And the, I was just talking about is like  the OODA loop is too long, right?  Like it's like these are like open tabs in my head  that stay open for somewhere between  three hours and three days.  And it's just like mentally uncomfortable.  That's hard.  And like, there's gonna be ways to make that easier.  But I think one of the better ways that I've done  is to take the same process and to use it  to how I interact with AI agents.  And it slows down the interaction  from a point of view of like,  just build this plan act done.  Like that's very quick.  But very quickly that goes off the reservation.  I've got no idea what code has been done  at any particular point in time.  It might've been that the first thing you did  broke everything and then you built 10 things  on top of that and I didn't know.  So actually getting it to step through  and do like one thing at a time  is like do a thing, test it, do a thing, test it,  do a thing, test it, do a thing, test it  in a way that I'm aware as the observer  and controller of the process, I'm constantly aware  and constantly seeing it being built.  I still have the massive momentum,  but I'm aware of exactly where we are in the process.  - Yes. - Like it's a huge difference  to like how easy it is to work with these coding tools.  - Yeah, I think we just started talking about this  before we fired up the pod.  Like maybe we should dive into this in a bit more detail  in terms of how you're using that tool, like practically.  You know like one of the things that I was saying  was like when I, 'cause I'm like, I started vibe coding  but I actually think this is more of a learning journey  for me, like I'm actually less concerned about the output.  At the end of the day I'm more concerned about  am I figuring out how to get there?  - Yeah, you build so you can learn how to build.  - Pretty much. - It's not like  I don't just want the thing.  I wanna know how to build things.  But equally I think I said this to you.  It's like, but if it works, how much does it matter?  You know like if I'm building something  that I'm trying to distribute, okay,  then there's a whole bunch of risks that are baked  into this code that I probably should be across  that I'm not across.  Okay, fair enough.  But if I'm using this for myself  and it's just locally on my MacBook,  I'm kind of like less concerned about that if it works.  And so like the thing that's been really powerful for me,  obviously like I use cursor.  And so I've got the agent running in cursor  and write a lot of the code.  And I'm not just sitting there  like accepting everything that comes through.  Like I can see what that's doing.  I can see the output.  And I'm like, okay, this isn't really what I asked for.  I might reject this and just go back a step  and just figure out like why it tried to do that thing.  But I'll also have Claude running on my monitor separately.  And Claude is like my project manager  or my technical co-founder on this.  And we've basically started there.  We've mapped out what the project should be.  We've like ideated and we've come up  with like essentially a roadmap or a PRD.  And then I will use Claude to essentially turn  that roadmap into like a sequential series of prompts  that I can feed back into cursor.  So that I can manage this like, you know,  risk of trying to one-shot everything,  which sometimes we'll try to do  if you just give it like an open mandate, it will go,  I'm going to build everything.  - And when it starts going, like it moves at such a speed  that you just, you can't even see, like you can watch it  and go, oh, that looks about right.  But like you're not reading anything  like it's moved to a new file.  It's made the new thing.  It's done that.  It's changed over here.  - Exactly.  - Oh, there we go.  I just made this quick change here,  which is introduced to bug.  It's just, it's an interesting challenge.  - Right, it's so easy to lose track  if this thing just goes off and like essentially just takes,  you know, goes cart launch.  I'm just going to build whatever the hell I want.  And you have no idea 'cause it's moved on so quickly.  I think like that sequential approach, I mean,  I adopted that for my own benefit  'cause I want to be able to, you know,  learn what's happening through this process.  And I sat and planned it out a lot  before I even jumped into cursor, which is the other thing.  It's like tempting to just go and open up cursor and go,  okay, build me this.  - I do it every now and again.  And I almost invariably then have to throw away  whatever it was that I can't use this  in any meaningful way, I'd rather.  Like, okay, it's figured out how to do that.  Like then maybe I get it to write like a documentation  of like how it did it.  And then you take that and move it forward.  So certainly like vibe prototyping  is a great thing to do.  - Well, there's a speed advantage there.  But the other thing is cursor,  like when it's done the steps that you've asked for  and the prompt, it will then give you the summary  of all the stuff it's done.  And so I will then copy that summary  and give it back to Claude and go,  look, this is what cursor has done.  So it's keeping track with me.  And I'll be like, okay, just talk to me about these steps.  So it's much slower, but I feel like I've got  a way better understanding of what's actually going on.  And then we tend to get, you know, an output that just works.  - So I think that's it is like, there's a tendency here  to just give into the tool and let it do its thing,  which is fine in certain environments.  - I think in others, you don't necessarily want to do that.  We haven't extracted the human yet.  There's still a human in the loop here.  They're not at the edge at the moment.  We can run human at the edge and it's probably good enough  for prototyping, ideation generation, stuff like this.  We could do, if we're actually building something  that you want that you're gonna have to deal with  after the fact or put your name to,  you can't quite extract the human yet.  And therefore you now need to think of,  well, all these tools are almost built  as though they run without the human.  And I need to figure out how do I slow them down enough  that I, again, I'm now in the UDA loop.  Because the problem with just general agent stuff  is the UDA loops are too fast.  And so I just abrogate responsibility and go,  yeah, you do your thing.  I just can't keep up.  Whereas if I can purposely slow it down to a level  where I'm like, look, I want, no, like here's your plan,  the great plan, right?  Give me 10 stages each with like a human testable thing  as the output of each stage, right?  Okay, here it is.  Okay, do only step one, and it does step one to freeze,  but it's close enough, right?  - Yeah. - Yeah, it's like,  and then you can actually test that what's been implemented  and now you understand how it's building  towards the end point.  And the difference might be that it's, in all honesty,  I think it's probably quicker  because the amount of time I end,  and cost of just credits to fix the crap that it just did,  because you have to like,  'cause at that point you're now maintaining  the context window for all that crap.  So you have this exponentially increasing cost of calls  as you move forwards with these models.  And it'll be like, oh yeah, that's a cent, that's a cent,  that's a cent, that's two cents, that's 10 cents,  that's a dollar.  And you're like, fuck that group quick.  - Yes.  - But it's like, oh, but if I don't then,  I'm gonna just, okay, I want a dollar, that's fine,  like it's fine.  But it moves you from this situation  where you might have been spending like,  I don't know, like 40 cents to build a new feature  is now $2, which is good.  Like that's still cheap for a software developer.  - Yeah, of course.  - But you're like, you know what?  It'd be good if I could just,  I'd be also happy to just do it in 50 cents  and actually understand what the fuck happened.  - Exactly.  - I can then build the next thing.  And I don't want to have to keep throwing away all this code.  There's definitely a lot of stuff  that I've just let it generate and thrown away.  I mean, sometimes you could have a project  which is just doing that in the background.  And then you have the one that you're building on  and it just gives you something to go and look at  and check in on that you don't really care about.  But it is giving you a proof of concept  about something that you know you need to build  and you just want to experiment with how you would build it.  And then you throw that away  and you take the bits that you learn  and you bring them into the project.  - I think what's been really handy for me  is being able to compartmentalize the kind of the,  let's say the feature or some aspect of the code  that I want to focus on.  And then I can keep iterating on that  because if you don't define those up front  and it just goes off and builds like 10 features,  none of them are necessarily perfect  or do exactly what you want.  So you need to then go back sequentially anyway.  So you may as well, if you've got the roadmap ahead of time  with something like a language model guiding you,  then all of a sudden it's like, I know what's coming up  but let me just focus on dialing in this one feature  and making sure that it's functional, it works.  It looks the way I want it to look.  All of those questions inevitably arise  but you haven't got this bloated code base  before you try to go back and make all those changes  and that impacts the core cost as well, right?  'Cause now you've just got one feature that you're building  and you're trying to perfect that  before you move on to feature number two  and then feature number three and then feature number four.  Whereas if you just build all four features  and all of a sudden it's got this much larger code base  to have to go and sift through  to figure out how to improve that very first feature.  And so I find I'm having to restart projects  way less than even a month ago.  'Cause often, yeah, it's the same thing.  It's just curiosity.  It's like, how hard is this thing to build?  Let me just try and clone it.  - What you're doing is you're speed running  rediscovering software development methodologies.  Turns out if you write a plan, it's better.  - It's good having a plan, couldn't you?  - Why didn't nobody say this?  I thought it was all I child and it's like,  yeah, no, like planning and thinking about the order  is a big thing.  - It makes sense.  - I mean, this is, I think I sometimes used to describe  the stack work version of like,  it's like really fast waterfall.  Like you wanna do the waterfall components  of like really thinking about it, designing it,  planning it, ordering what you're gonna do  and then do one thing at a time until it's done.  It's just instead of that taking you a six month iteration,  now it takes like two minutes.  Whereas like the agile component was like,  ah, we'll work at like a very quick human speed.  But then as soon as you try and work like that  with something that's not working at a human speed  and it's working at like a thousand times human speed,  fuck me, that's just, it just like,  it takes it out of your, I don't know,  like mental perception or something.  It just doesn't work, you need a different approach.  And I think like just very fast waterfall  is probably the bionic human version of that.  And then at some point we figure out  how to meaningfully do the planning and architecture piece.  And then I think it just,  software becomes basically free at that point.  - I think the other thing that really helps  is when you're building for yourself,  like you innately understand the problem that you've got.  You're never trying to guess at like,  will my market use this in,  does it need to be a certain way for a particular market  that I'm trying to build for?  It's like, it's immaterial,  I'm trying to build this for myself.  I've got a problem, this is how I would use this tool.  And I just find that so much easy to work through  because I don't need to second guess  any of the things that I'm doing.  I can just see the output and go,  no, I would prefer this looked a bit different.  You know, I'd prefer like a set of steps  that help me walk me through this.  - Dude, the whole thing again.  - Yeah, okay.  - You can be the like really just intolerant  like product lead, just come and go,  no, it's all wrong, do it again.  Stop it from scratch.  - It's only gonna cost $2, fuck it.  - Do you know, it's funny,  sometimes like when I'm doing the roadmap with Claude,  it will put timeframes next to it and it will be like,  oh, this part should take 12 weeks.  And I'm just like, oh, lol.  Watch me come back to you in 10 minutes.  - Yeah, it is insane, like how much,  like the speed of iteration here is just really ramped up.  But all right, I mean, we're coming up on an hour now,  we need a title, like we've got,  I think maybe Rise of the Generalist.  - Yeah, that's actually quite nice.  We did spend a lot of time on that.  - Done, is there a famous general?  Is there like a pun that we could have?  Is there a general robot thing?  - I don't know. - I don't know.  All right, something like that, Rise of the Generalist.  - I think that works, it's descriptive.  We did spend a lot of time on Generalist.  - Perfect, Rise of the Generalist.  - This is cool, at some point we should probably like  talk about some of the tools that we're building as well.  - Yes, yeah, I wonder if we might get into that  a bit more today, but it's, what are we at?  One out of 10, I reckon we do that.  - Next week. - Next week, business on air.  Let's do it next week.  All right, oh, we do have like potentially some guests  as well. - Oh, we do, yeah.  - To bring in, so let's see how we can schedule those.  So next week, maybe we get a guest,  maybe we go into tooling, but let's go there.  - We'll see, we'll see. - All right.  - Awesome. - That's the good stuff.
